{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset site\n",
    "# https://bop.felk.cvut.cz/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%wget` not found.\n"
     ]
    }
   ],
   "source": [
    "# %wget http://ptak.felk.cvut.cz/6DB/public/bop_datasets/lm_train_pbr.zip\n",
    "\n",
    "# export SRC=http://ptak.felk.cvut.cz/6DB/public/bop_datasets\n",
    "# wget $SRC/lm_base.zip         # Base archive with dataset info, camera parameters, etc.\n",
    "# wget $SRC/lm_models.zip       # 3D object models.\n",
    "# wget $SRC/lm_test_all.zip     # All test images (\"_bop19\" for a subset used in the BOP Challenge 2019/2020).\n",
    "# wget $SRC/lm_train_pbr.zip    # PBR training images (rendered with BlenderProc4BOP).\n",
    "\n",
    "# unzip lm_base.zip             # Contains folder \"lm\".\n",
    "# unzip lm_models.zip -d lm     # Unpacks to \"lm\".\n",
    "# unzip lm_test_all.zip -d lm   # Unpacks to \"lm\".\n",
    "# unzip lm_train_pbr.zip -d lm  # Unpacks to \"lm\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "1. Dataset class (Currently {recyclable: 0, non-recyclable: 1})\n",
    "2. How to use dataset\n",
    "3. Crop image from bound box\n",
    "4. Optimize NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_size = (100, 100)\n",
    "camera_parameter = []\n",
    "\n",
    "def crop(image, bound_box):\n",
    "    pass\n",
    "\n",
    "def resize(image):\n",
    "    return cv2.resize(image, result_size, cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class Dataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         pass\n",
    "\n",
    "#     def __len__(self):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super.__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "    self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "    self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "    self._to_linear = None\n",
    "\n",
    "    x = torch.randn(result_size[0], result_size[1]).view(-1,1,result_size[0], result_size[1]) # init\n",
    "    self._to_linear = None\n",
    "    self.convs(x)\n",
    "\n",
    "    self.fc1 = nn.Linear(self._to_linear, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 2)\n",
    "    \n",
    "\n",
    "  def convs(self, x):\n",
    "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "    x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "    x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "    if self._to_linear is None:\n",
    "      self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "      return x\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    result = F.softmax(self.fc2(x), dim=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ไม่เกี่ยว\n",
    "def train(net):\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "            #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "            net.zero_grad()\n",
    "\n",
    "            outputs = net(batch_X)\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()    # Does the update\n",
    "\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "MAX_EPOCH = 1000\n",
    "optimizer = optim.Adam(lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "loss_history = []\n",
    "batch_size = 16\n",
    "\n",
    "def train():\n",
    "    model = Net()\n",
    "    for epoch in MAX_EPOCH:\n",
    "        samples = []\n",
    "        total_loss = 0\n",
    "        for X, y in samples:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = loss_fn(X, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss\n",
    "        loss_history.append(total_loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model = Net()\n",
    "    samples = []\n",
    "    total_loss = 0\n",
    "    for X, y in samples:\n",
    "        output = model(X)\n",
    "        loss = loss_fn(X, y)\n",
    "        total_loss += loss\n",
    "    loss_history.append(total_loss)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2312e55fce8892ca5a2892186c6ef6b6c1a9387f6adc0b1ef4b759e8dcf769bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
